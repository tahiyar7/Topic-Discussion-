{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# The Notebook is designed to get you all the necessary libraries for your model. Thanks. ","metadata":{}},{"cell_type":"code","source":"# Langchain \nfrom torch import cuda, bfloat16\nimport torch \nimport transfromers \nfrom transformers import AutoTokenizer\nfrom time import time \nimport chromadb\nfrom chromadb.comfig import Settings\nfrom langchain.llms import HuggingFacePipeline\nfrom langchain.document_loaders import TextLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.embeddings import HiggingFaceEmbeddings\nfrom langchain.chains import RetrievalQA\nfrom langchain.vectorstores import Chroma\n\n\nfrom langchain.embeddings.openai import OpenAIEmbeddings \nfrom langchain.document_loaders import PyPDFLoader\nfrom langchain.text_splitter import CharacterTextSplitter \nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.chains import RetrievalQA\n\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter \nfrom langchain import PromptTemplate, LLMChain \nfrom langchain.vectorstores import FAISS\nfrom langchain.llms import HiggingFAcePipeline \nfrom langchain.embeddings import HuggingFaceInstructEmbeddings \nfrom langchain.chains import RetrievalQA\n\nfrom transformers import AutoTokenizer\nfrom transformers import AutoTokenizer, pipeline\n\n\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#LDA\nfrom collections import Counter\nfrom scipy.misc import imread\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.decomposition import NMF, LatentDirichletAllocation\nfrom matplotlib import pyplot as plt\n\n\nfrom nlpy import topic_modeling\n\n# Example of fitting an LDA model\nlda_model = topic_modeling.LDA(num_topics=10)\nlda_model.fit(documents)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Gensim \nimport gensim\nfrom gensim import corpora, models\n\n# Example of creating a dictionary and corpus\ndictionary = corpora.Dictionary(documents)\ncorpus = [dictionary.doc2bow(doc) for doc in documents]\n\n# LDA model\nlda_model = models.LdaModel(corpus, num_topics=10, id2word=dictionary)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Scikit Learn \nfrom sklearn.decomposition import LatentDirichletAllocation\nfrom sklearn.feature_extraction.text import CountVectorizer\n\n# Example of creating a document-term matrix\nvectorizer = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')\ndtm = vectorizer.fit_transform(documents)\n\n# LDA model\nlda = LatentDirichletAllocation(n_components=10, random_state=0)\nlda.fit(dtm)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Spacy\nimport spacy\n\nnlp = spacy.load(\"en_core_web_sm\")\ndoc = nlp(\"Example text for preprocessing\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Bertopic \nfrom bertopic import BERTopic\n\ntopic_model = BERTopic()\ntopics, _ = topic_model.fit_transform(documents)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Top2Vec\nfrom top2vec import Top2Vec\n\nmodel = Top2Vec(documents)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Mallet \nfrom gensim.models.wrappers import LdaMallet\n\nmallet_path = 'path/to/mallet'  # Update this path\nlda_mallet = LdaMallet(mallet_path, corpus=corpus, num_topics=10, id2word=dictionary)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# PyLDAVIS\nimport pyLDAvis\nimport pyLDAvis.gensim_models as gensimvis\n\nlda_display = gensimvis.prepare(lda_model, corpus, dictionary)\npyLDAvis.show(lda_display)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Tomotopy\nimport tomotopy as tp\n\n# Create an LDA model and add documents\nmdl = tp.LDAModel(k=10)\nfor doc in documents:\n    mdl.add_doc(doc)\n\n# Train the model\nmdl.train(100)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#NLPY\nfrom nlpy import topic_modeling\n\n# Example of fitting an LDA model\nlda_model = topic_modeling.LDA(num_topics=10)\nlda_model.fit(documents)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Clustering  BERTOPIC * HUGGINGFACE\nfrom transformers import BertModel, BertTokenizer\nimport torch\nfrom sklearn.cluster import KMeans\n\n# Load pre-trained BERT model and tokenizer\nmodel = BertModel.from_pretrained('bert-base-uncased')\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n\n# Tokenize and get embeddings\ndocuments = [\"Sample text for topic modeling\", \"Another document for the same task\"]\ninputs = tokenizer(documents, return_tensors='pt', padding=True, truncation=True)\nwith torch.no_grad():\n    outputs = model(**inputs)\nembeddings = outputs.last_hidden_state.mean(dim=1).numpy()\n\n# Cluster embeddings\nn_clusters = 10\nkmeans = KMeans(n_clusters=n_clusters)\nkmeans.fit(embeddings)\nlabels = kmeans.labels_\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#BERTopic (Leveraging Hugging Face models):\nfrom bertopic import BERTopic\nfrom transformers import pipeline\n\n# Use a pre-trained Hugging Face transformer model for embeddings\ntransformer_model = pipeline(\"feature-extraction\", model=\"distilbert-base-uncased\")\n\n# Sample documents\ndocuments = [\"Sample text for topic modeling\", \"Another document for the same task\"]\n\n# Initialize and fit BERTopic model\ntopic_model = BERTopic(embedding_model=transformer_model)\ntopics, _ = topic_model.fit_transform(documents)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Hugging Face Datasets:\nfrom datasets import load_dataset\n\n# Load a dataset\ndataset = load_dataset('ag_news')\n\n# Preprocess and tokenize\nfrom transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\ndef preprocess(examples):\n    return tokenizer(examples['text'], truncation=True, padding='max_length')\n\ntokenized_dataset = dataset.map(preprocess, batched=True)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#GPT 3 TURBO\nfrom transformers import GPT2LMHeadModel, GPT2Tokenizer\n\n# Load pre-trained GPT-2 model and tokenizer\nmodel = GPT2LMHeadModel.from_pretrained('gpt2')\ntokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n\n# Generate text\ninput_text = \"Topic modeling is\"\ninputs = tokenizer.encode(input_text, return_tensors='pt')\noutputs = model.generate(inputs, max_length=50)\ngenerated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(generated_text)\n","metadata":{},"execution_count":null,"outputs":[]}]}